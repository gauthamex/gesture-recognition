# âœ‹ Hand Gesture Recognition using CNN (PyTorch)

This project implements a **Convolutional Neural Network (CNN)** in **PyTorch** to classify hand gestures using the **LeapGestRecog dataset**. The model learns to recognize different hand gestures from grayscale images and achieves high accuracy.

---

## ğŸ“‚ Dataset

We use the **[LeapGestRecog dataset](https://www.idiap.ch/en/dataset/leapgestrecog)** which contains:

* **10 users**
* **10 gesture classes** (e.g., palm, fist, thumb, index, ok, etc.)
* Each gesture has **200 images per user** â†’ \~20,000 images total

Directory structure:

```
leapGestRecog/
â”‚â”€â”€ 00/
â”‚   â”œâ”€â”€ 01_palm/
â”‚   â”œâ”€â”€ 02_fist/
â”‚   â”œâ”€â”€ ...
â”‚â”€â”€ 01/
â”‚   â”œâ”€â”€ 01_palm/
â”‚   â”œâ”€â”€ 02_fist/
â”‚   â”œâ”€â”€ ...
```

---

## âš™ï¸ Workflow

1. **Load Dataset** â€“ Images loaded in grayscale, resized to `64x64`.
2. **Preprocessing** â€“ Normalization (pixel values scaled to `[0,1]`).
3. **Dataset Split** â€“ 80% training, 20% testing.
4. **PyTorch Dataset & DataLoader** â€“ For efficient training.
5. **CNN Model** â€“

   * Conv2D â†’ ReLU â†’ MaxPool
   * Conv2D â†’ ReLU â†’ MaxPool
   * Fully Connected Layers + Dropout
6. **Training** â€“ CrossEntropyLoss + Adam optimizer.
7. **Evaluation** â€“ Compute test accuracy.
8. **Save Model** â€“ Trained weights saved as `hand_gesture_model.pth`.

---

## ğŸ§  Model Architecture

```
Input: 1 x 64 x 64 (grayscale image)

[Conv2D(1â†’32, kernel=3) + ReLU + MaxPool(2)]
[Conv2D(32â†’64, kernel=3) + ReLU + MaxPool(2)]
[Flatten]
[FC: 64*14*14 â†’ 128 + ReLU + Dropout(0.5)]
[FC: 128 â†’ num_classes]

Output: Gesture Class
```

---

## ğŸ“Š Results

* **Training**: 10 epochs
* **Loss**: decreases steadily
* **Accuracy**: \~95% (varies per run & system)

Example output:

```
Epoch 1, Loss: 102.2345
Epoch 2, Loss: 87.4562
...
Epoch 10, Loss: 34.1278
Training finished.
Test Accuracy: 95.42%
Model saved as hand_gesture_model.pth
```

---

## ğŸš€ Installation & Usage

1. Clone this repository:

   ```bash
   git clone https://github.com/your-username/hand-gesture-recognition.git
   cd hand-gesture-recognition
   ```

2. Install dependencies:

   ```bash
   pip install -r requirements.txt
   ```

3. Download the **LeapGestRecog dataset** and place it in the project folder.

4. Run training:

   ```bash
   python hand_gesture_recognition.py
   ```

5. Trained model will be saved as `hand_gesture_model.pth`.

---

## ğŸ“¦ Requirements

* Python 3.x
* OpenCV (`cv2`)
* NumPy
* scikit-learn
* PyTorch

---

## ğŸ“Œ Applications

* Human-computer interaction
* Virtual reality / AR gesture input
* Assistive technologies
* Robotics control via hand gestures

---

## ğŸ¤ Contributing

Contributions, issues, and feature requests are welcome!
Feel free to fork this repo and submit a pull request.

